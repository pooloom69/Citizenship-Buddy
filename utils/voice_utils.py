import streamlit as st
import base64
from openai import OpenAI

def get_client():
    # ì—¬ëŸ¬ Key nameì„ ëŒ€ì‘ (Cloud í˜¸í™˜)
    for key in ["OPENAI_API_KEY", "openai_api_key", "OPENAI", "openai"]:
        if key in st.secrets:
            return OpenAI(api_key=st.secrets[key])
    raise ValueError("â— OpenAI API Key not found in Streamlit secrets.")

# --------------------------------------------------------------
# ğŸ§ TEXT â†’ SPEECH (ëª¨ë°”ì¼ ì™„ì „ í˜¸í™˜)
# --------------------------------------------------------------
def play_tts(text):
    client = get_client()

    # 1) TTS ìƒì„±
    response = client.audio.speech.create(
        model="gpt-4o-mini-tts",
        voice="alloy",
        input=text
    )

    # 2) ë°”ì´íŠ¸ë¡œ ë³€í™˜
    audio_bytes = response.read()

    # 3) base64ë¡œ ì¸ì½”ë”©
    audio_b64 = base64.b64encode(audio_bytes).decode()

    # 4) HTML audio íƒœê·¸ë¡œ ë„£ê¸° (ëª¨ë°”ì¼ 100% ì§€ì›)
    st.markdown(
        f"""
        <audio controls>
            <source src="data:audio/mp3;base64,{audio_b64}" type="audio/mp3">
        </audio>
        """,
        unsafe_allow_html=True
    )

# --------------------------------------------------------------
# ğŸ¤ RECORD + WHISPER STT
# --------------------------------------------------------------
def record_and_transcribe():
    client = get_client()

    audio = st.audio_input("ğŸ¤ Record your voice")
    if audio is None:
        return None

    with st.spinner("ğŸ“¥ Transcribing your recording..."):
        transcript = client.audio.transcriptions.create(
            model="whisper-1",    # â† ë°˜ë“œì‹œ whisper-1!
            file=audio
        )
        text = transcript.text

    st.success("ğŸ‰ Transcription completed!")
    st.markdown(f"ğŸ—£ï¸ You said: **{text}**")
    return text
